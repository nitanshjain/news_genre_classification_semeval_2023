{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import regex as re\n",
    "import spacy as sy\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "\n",
    "nlp_en = sy.load('en_core_web_sm')\n",
    "all_stopwords = nlp_en.Defaults.stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/Sem_Eval/semeval2023task3/preprocessed_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['id', 'keyword', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(y, df):\n",
    "    \n",
    "    pos_tags_final_text = list()\n",
    "    er_final_text = list()\n",
    "    preprocessed_text = list()\n",
    "\n",
    "    for x in df.loc[:,y]:\n",
    "\n",
    "        tokenizer = TweetTokenizer()\n",
    "        #tokenizing\n",
    "        doc = tokenizer.tokenize(x)\n",
    "        \n",
    "        # removing links\n",
    "        tokens = [token for token in doc if not urlparse(token).scheme]\n",
    "        x = ' '.join(tokens)\n",
    "        doc = nlp_en(x)\n",
    "        \n",
    "        # removing punctuation and white space\n",
    "        tokens = [token.orth_ for token in doc if not token.is_punct | token.is_space]    \n",
    "        x = ' '.join(tokens)\n",
    "        \n",
    "        # lower case\n",
    "        x = x.lower()\n",
    "        doc = nlp_en(x)\n",
    "\n",
    "        # lemmatization\n",
    "        tokens = [word.lemma_ for word in doc]   \n",
    "        x = ' '.join(tokens)\n",
    "        doc = nlp_en(x)  \n",
    "        \n",
    "        # removing punctuation and white space\n",
    "        tokens = [token.orth_ for token in doc if not token.is_punct | token.is_space]    \n",
    "        x = ' '.join(tokens)\n",
    "        doc = nlp_en(x)\n",
    "        \n",
    "        # removing individual letters\n",
    "        tokens = [word.text for word in doc if len(word)>=2]\n",
    "        x = ' '.join(tokens)  \n",
    "        \n",
    "        # removing numbers\n",
    "        x = re.sub(r'\\d+', '', x)\n",
    "        x = re.sub(' +', ' ', x)\n",
    "        doc = nlp_en(x)\n",
    "        \n",
    "         # removing hashtags and mentions\n",
    "        tokens = [word.text for word in doc if word.text[0] not in ('#', '@')]\n",
    "        x = ' '.join(tokens)\n",
    "        doc = nlp_en(x)\n",
    "        \n",
    "        # removing stop words\n",
    "        tokens = [word for word in doc if not word in all_stopwords]\n",
    "        list_of_strings  = [i.text for i in tokens]\n",
    "        x = ' '.join(list_of_strings)\n",
    "        doc = nlp_en(x)\n",
    "        \n",
    "        # Part of speech tagging\n",
    "        pos_tags = [(i, i.tag_) for i in doc]\n",
    "        pos_tags_final_text.append(pos_tags)\n",
    "        \n",
    "        # entity recognition tagging\n",
    "        er =  [(i, i.label_, i.label) for i in doc.ents] \n",
    "        er_final_text.append(er)\n",
    "        \n",
    "        preprocessed_text.append(x)\n",
    "        \n",
    "    return pos_tags_final_text, er_final_text, preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_final_text, er_final_text, preprocessed_text = preprocessing('text', test_df)\n",
    "\n",
    "test_df['preprocessed_text'] = preprocessed_text\n",
    "test_df['pos_tags_text'] = pos_tags_final_text\n",
    "test_df['er_tags_text'] = er_final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/nitanshjain/Documents/Projects/Sem_Eval/semeval2023task3/preprocessed_data/extra_test.csv'\n",
    "test_df.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sem_Eval-qQJYuRaW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5bd67ae72067af90d04bfe162c4dbae485f2bc9cd35e8ebfff36ec4914b703f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
